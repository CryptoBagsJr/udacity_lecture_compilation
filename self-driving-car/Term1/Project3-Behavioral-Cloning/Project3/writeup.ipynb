{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Behavioral Cloning*\n",
    "\n",
    "## Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Behavioral Cloning Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Use the simulator to collect data of good driving behavior\n",
    "* Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "* Train and validate the model with a training and validation set\n",
    "* Test that the model successfully drives around track one without leaving the road\n",
    "* Summarize the results with a written report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/placeholder.png \"Model Visualization\"\n",
    "[image2]: ./examples/placeholder.png \"Grayscaling\"\n",
    "[image3]: ./examples/placeholder_small.png \"Recovery Image\"\n",
    "[image4]: ./examples/placeholder_small.png \"Recovery Image\"\n",
    "[image5]: ./examples/placeholder_small.png \"Recovery Image\"\n",
    "[image6]: ./examples/placeholder_small.png \"Normal Image\"\n",
    "[image7]: ./examples/placeholder_small.png \"Flipped Image\"\n",
    "\n",
    "## Rubric Points\n",
    "### Here I will consider the [rubric points](https://review.udacity.com/#!/rubrics/432/view) individually and describe how I addressed each point in my implementation.  \n",
    "\n",
    "---\n",
    "### Files Submitted & Code Quality\n",
    "\n",
    "#### 1. Submission includes all required files and can be used to run the simulator in autonomous mode\n",
    "\n",
    "My project includes the following files:\n",
    "* model.py containing the script to create and train the model\n",
    "* train_network.ipynb: the original ipython notebook (model.py is exported from this file)\n",
    "* drive.py for driving the car in autonomous mode\n",
    "* model.h5 containing a trained convolution neural network \n",
    "* writeup.pdf (and writeup.ipynb) summarizing the results\n",
    "\n",
    "\n",
    "#### 2. Submission includes functional code\n",
    "Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing\n",
    "\n",
    "```sh\n",
    "python drive.py model.h5\n",
    "```\n",
    "\n",
    "#### 3. Submission code is usable and readable\n",
    "\n",
    "The model.py file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture and Training Strategy\n",
    "\n",
    "I've tried three different model architectures:\n",
    "* a model with only Conv2D and Dense layers\n",
    "* a model using Dropout to avoid overfitting.\n",
    "* a model using Dropout and Max Pooling to avoid overfitting\n",
    "\n",
    "\n",
    "#### 1. An appropriate model architecture has been employed\n",
    "\n",
    "\n",
    "**Model 1: a model using only Conv2D and Dense layers**\n",
    "* When training only with Conv2D and Dense, the model was trained rapidly and the loss has reduced quickly. \n",
    "* However, the validation loss didn't drop and was oscillating within around 0.04 of validation loss.\n",
    "* It means the model is suffering from overfitting.\n",
    "\n",
    "\n",
    "The following tables shows the model architecture:\n",
    "\n",
    "<img src='./writeup-assets/model1.png' width=600px>\n",
    "\n",
    "As you can see in the graph below, the loss values decrease quite fast and well enough (0.0039), but the validation loss didn't decreased, but diverged after 4 epochs.\n",
    "\n",
    "<img src='./writeup-assets/loss-graph1.png' width=600px>\n",
    "\n",
    "The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track. The vehicle was successfully on the track for two laps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Attempts to reduce overfitting in the model\n",
    "\n",
    "**Model 2: a model with Dropout**\n",
    "* To fix the overfitting, we tried to apply Dropout layers on several layers.\n",
    "* With Dropout, I had to increase the epoch count because the loss value was reduced  much slower than when trained without Dropout.\n",
    "* The validation loss seemed decreasing at first few epochs, but after that it diverged again \n",
    "* I applied Dropout only three times for convolutional network, and two times for fully connected networks. \n",
    "    * When I tried to apply Dropout to every layer, the model was trained very slowly, and also the loss didn't reduce much.\n",
    "\n",
    "\n",
    "The following tables shows the model architecture:\n",
    "\n",
    "<img src='./writeup-assets/model2.png' width=600px>\n",
    "\n",
    "As you can see in the graph below, the loss values decrease not that fast as the previous model did and didn't get good loss values within 30 epochs. The average of the validation loss was a little smaller than the model1\n",
    "lodecreased, but diverged badly after 15 epochs.\n",
    "\n",
    "<img src='./writeup-assets/loss-graph2.png' width=600px>\n",
    "\n",
    "The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track. The vehicle was successfully on the track for two laps, althouth it hit the guardrail on the right on the bridge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 3: a model with Dropout and Pooling**\n",
    "\n",
    "* Another try to fix the overfitting was to add Pooling layers on several layers.\n",
    "* To be able to apply Pooling layers, we added a Conv2D layer with (3, (1, 1)) at the front of the model to represent color space.\n",
    "\n",
    "\n",
    "The following tables shows the model architecture:\n",
    "\n",
    "<img src='./writeup-assets/model3.png' width=600px>\n",
    "\n",
    "As you can see in the graph below, the validation loss seemed lower than the previous models, but the overall loss value is higher and not decreasing fast enough. Even with epochs=50, the loss remained as 0.0421, which is a lot higher than other previous models.\n",
    "\n",
    "\n",
    "<img src='./writeup-assets/loss-graph3.png' width=600px>\n",
    "\n",
    "The model was tested by running it through the simulator, and the vehicle could not successfully stay on the track. I think it was that the model was not trained well enough and it ended with the loss of 0.0421 which is relatively high.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model parameter tuning\n",
    "\n",
    "* The model used an adam optimizer, so the learning rate was not tuned manually.\n",
    "* epochs = 30 for the model1 and the model2, and 50 for the model3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Creation of the Training Set  and Appropriate training data\n",
    "\n",
    "I used three data (data1, data2 and data3) for training.\n",
    "\n",
    "* data1: the data captured from the simulator while I tried to drive the car in the center of the lane. The data were generated for two laps.\n",
    "* data2: the data captured from the simulator while I tried to drive the car in recovery driving, that is, I tried to move the car to the edge of each side of the lane and then quickly move back to the center, and keep doing that repeatedly. The data is for two laps.\n",
    "* data3: the data captured from the simulator while I drived the car in reverse way (counter clockwise). The data is for two laps.\n",
    "\n",
    "The input images are normalized to -0.5 to 0.5 by using Lamda function in Keras.\n",
    "```\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "```\n",
    "\n",
    "**Using the images from the left and the right cameras**\n",
    "I used three images per every shot - the images captured by the center, the left and the right cameras. \n",
    "For the images from the left and the right cameras, we adjusted the camera angle by a correction factor (0.2).\n",
    "\n",
    "<img src='./writeup-assets/camera-images.png' width=900px>\n",
    "\n",
    "**Cropping**\n",
    "\n",
    "I cropped the top portion (70 pixcels) of the image to remove the distracting background, and also bottom portion (25 pixels) of the images to remove the hood part of the car.\n",
    "The resulting image is shown below.\n",
    "\n",
    "<img src='./writeup-assets/cropping.png' width=400px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. Solution Design Approach\n",
    "\n",
    "The overall strategy for deriving a model architecture was to start with a simple Convolution network, and then apply additional layers for reducing overfitting if needed.\n",
    "\n",
    "However, when I applied the Dropout, the average validation loss seemed a little lowered, but the traning time took a lot much longer, and also the resulting validation loss was not improved much.\n",
    "\n",
    "When I added pooling layers, the model could not trained well enough, meaning the model was training a lot much slower and the validation loss was not improved. \n",
    "\n",
    "\n",
    "I have tried several other configurations of layers, and also turn on and off the pooling and dropout (with several different dropout rate), but I could not successfully improve the validation loss.\n",
    "\n",
    "\n",
    "#### 2. Final Model Architecture\n",
    "\n",
    "\n",
    "The final model architecture I used for the simulator is the Model1 only with Conv2D and Dense layers, without Dropout and Pooling, because the model showed the best loss value, and the validation loss was not that bad compared to other models. \n",
    "\n",
    "\n",
    "\n",
    "#### 3. Creation of the Training Set & Training Process\n",
    "\n",
    "Please see the description above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
